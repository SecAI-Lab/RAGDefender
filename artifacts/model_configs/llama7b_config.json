{
    "model_info":{
        "provider":"llama",
        "name":"meta-llama/Llama-2-7b-chat-hf"
    },
    "api_key_info":{
        "api_keys":[
            "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"
        ],
        "api_key_use": 0
    },
    "params":{
        "temperature":0.1,
        "seed":100,
        "gpus":[0],
        "device":"cuda",
        "max_output_tokens":150,
        "repetition_penalty":1.0,
        "max_gpu_memory":"7GiB",
        "revision":"main",
        "load_8bit":"True",
        "debug":"False",
        "cpu_offloading":"False"
    }
}